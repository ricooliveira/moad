---
title: "R Notebook"
output: html_notebook
---

```{r}

if (!require("dplyr")) {
  install.packages("dplyr", repos="http://cran.rstudio.com/") 
}
if (!require("data.table")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("pbapply")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("ggplot2")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("reshape")) {
  install.packages("reshape", repos="http://cran.rstudio.com/") 
}

library(dplyr)
library(data.table)
library(pbapply)
library(ggplot2)
library(reshape)
library(lsa)

```

```{r}

REC.SIZE = 10
address <- "/home/ricardo/DataScience/moad/"

# aspects setup
# aspects: 1 = "Contemporaneity", 2 = "Locality", 3 = "Genre")
#for(aspect.index in 1:4){
aspects.all = c(1,2,3)
aspects.not.to.diversify = c(3)
aspects.to.diversify = setdiff(aspects.all,aspects.not.to.diversify)

```

```{r}

########################################## Metric Functions ##########################################

# Intra List Diversity Metric (ILD)

similarity.function.genre = function(data){
  return(cosine(t(as.matrix(data))))
}

similarity.function.locality = function(data){
  n = nrow(data)
  m = matrix(0L,n,n)
  N = nrow(artist.data)
  for(i in 1:n){
    for(j in 1:n){
      if(data[i,"area"] == data[j,"area"]){
        m[i,j] = 1
      } else {  
        m[i,j] = 1 / (1 + log10(N/(as.numeric(freq.area[which(data[i,"area"] == freq.area$area),"total"]))) 
                        * log10(N/(as.numeric(freq.area[which(data[j,"area"] == freq.area$area),"total"]))))
      }
    }
  }
  return(m)
}

similarity.function.contemporaneity = function(data){
  artistas = rownames(data)
  data$artista = artistas
  artist_simi = combn(artistas, 2) %>% t() %>% as_data_frame()

  sim_between_artists = function(x, data){
    a = x[1]
    b = x[2]
    a_data =  data %>% filter(artista %in% a)
    b_data =  data %>% filter(artista %in% b)
    
    pc = min(a_data$debut, b_data$debut)
    ut = max(a_data$last, b_data$last)
    
    uc = max(a_data$debut, b_data$debut)
    pt = min(a_data$last, b_data$last)
    
    if (ut == pc)
      return(1)
    
    sim = (pt - uc)/(ut - pc)
    return((sim+1)/2)
  }
  
  sim = apply(artist_simi, 1, sim_between_artists, data)
  artist_simi$sim = sim
  artist_simi_replicated = artist_simi %>% select(V1=V2, V2=V1, sim)
  artists_identity = data.frame(V1 = artistas, V2 = artistas, sim = 1)
  artist_simi = rbind(artist_simi, artist_simi_replicated, artists_identity)
  
  matrix = artist_simi %>% cast(V1~V2, mean, value = "sim") %>% select(-V1)
  
  matrix = matrix %>% as.matrix()
  return(matrix)
}

ILD = function(data, similarity.function){
  k=nrow(data)
  if(k > 1){
    sum.dissimilarity = 0
    similarity.matrix = similarity.function(data)
    dissimilarity.matrix = 1 - similarity.matrix
    sum.dissimilarity = sum(colSums(dissimilarity.matrix))
    return(sum.dissimilarity/(k*(k-1)))
  }else{
    return(0)
  }
}

# Distance List History Metric (DLH)

distance.function.genre = function(data, history){
  centroid = genre.centroids[which(genre.centroids$`user-id` == user),]
  centroid$`user-id` = NULL
  distance = 0
  for(i in 1:nrow(data)){
    distance = distance + cosine(as.vector(t(data[i,])),as.vector(t(centroid)))
  }
  return(distance/nrow(data))
}

distance.function.locality = function(data, history){
  rec <- as.vector(t(data))
  h <- as.vector(t(history))
  
  rec.g <- sapply(rec, function(x) {freq.area[which(x == freq.area$area), ]$total})
  h.g <- sapply(h, function(x) {freq.area[which(x == freq.area$area), ]$total})
  
  f <- function(i, j) {
    ifelse(i == j, 1, 1 / (1 + log10(N/i) * log10(N/j)))
  }
  
  r <- outer(rec.g, h.g, f)
  return(mean(r))
}

distance.function.contemporaneity = function(data, history){

  n = nrow(data)
  m = nrow(history)
  data$index = c(1:nrow(n))
  history$index = c(1:nrow(m))
  # artist_simi = combn(artistas, 2) %>% t() %>% as_data_frame()

  sim_between_artists_history = function(x, data, history){
    a = x[1]
    b = x[2]
    a_data =  data %>% filter(index %in% a)
    b_history =  history %>% filter(index %in% b)
    
    pc = min(a_data$debut, b_history$debut)
    ut = max(a_data$last, b_history$last)
    
    uc = max(a_data$debut, b_history$debut)
    pt = min(a_data$last, b_history$last)
    
    sim = (pt - uc)/(ut - pc)
    
    return((sim+1)/2)
  }
   
  sum.contemporaneity = 0
  for(i in 1:n){
    for(j in 1:m){
      sum.contemporaneity = sum.contemporaneity + sim_between_artists_history(c(i,j), data, history)
    }
  }
  return(sum.contemporaneity / (m * n))
}

DLH = function(data, history, distance.function){
  return(distance.function(data, history))
}

```

```{r}

########################## DATA LOAD ############################

data.train <- fread(paste0(address,"data/LFM_train.txt"), 
                    sep = "\t", 
                    verbose = TRUE,
                    header = TRUE)
data.train = as.data.frame(data.train)

# data.test <- fread(paste0(address,"data/LFM_test.txt"), 
#                     sep = "\t", 
#                     verbose = TRUE,
#                     header = TRUE)
# data.test = as.data.frame(data.test)

artist.data <- fread(paste0(address,"data/artist.data.txt"), 
                     sep = ";", 
                     verbose = TRUE,
                     header = TRUE)
artist.data = as.data.frame(artist.data)

# Correcting debut year from Rod Stewart - wrong in MusicBrainz

artist.data[which(artist.data$Artist == "The_Pains_of_Being_Pure_at_Heart"),"last"] = 2017
artist.data[which(artist.data$Artist == "Rod_Stewart"),"debut"] = 1968

# Input 0 in NA values

col = c(3:6)
for(i in col){
  artist.data[which(is.na(artist.data[,i])),i] = 0
}

genre.centroids <- fread(paste0(address,"data/user.history.centroids.txt"), 
                    sep = ",", 
                    verbose = TRUE,
                    header = TRUE)
genre.centroids = as.data.frame(genre.centroids)

users = data.train$`user-id` %>% unique()

```

```{r}

################################ OBJECTIVE FUNCTION ################################

# This function will be executed for a user, with specific data.test, specified aspects to diversify and a determined 
# list size (TOPN)

# list.elements.index = rec.list

multi.objective = function(list.elements.index){
   size = length(list.elements.index)
   list.elements = as.data.frame(artist.data[list.elements.index,"Artist"])
   names(list.elements) = "artist"
   n = length(aspects.to.diversify)
   df = artist.data[artist.data$Artist %in% list.elements$artist,]
   
   sum.ild = 0
   for(i in aspects.to.diversify){
     df.aspect = df[(aspects[[i]])]
     sum.ild = sum.ild + ILD(data = df.aspect, similarity.function = similarity.functions[[i]])
   }
   y1 = (sum.ild / n)
   
   sum.dlh = 0
   for(i in aspects.not.to.diversify){
     df.aspect = df[(aspects[[i]])]
     sum.dlh = sum.dlh + DLH(data = df.aspect, history = data.train.user[(aspects[[i]])], distance.function = distance.functions[[i]])
   }
   y2 = (sum.dlh / length(aspects.not.to.diversify))
   
   return(c(y1, y2))
}

```

```{r}

########################################## ASPECTS ##########################################

aspects <- vector(mode="list", length=3)
names(aspects) <- c("Contemporaneity", "Locality", "Genre")
aspects[[1]] <- c(5,6); aspects[[2]] <- 4; aspects[[3]] <- 7:ncol(artist.data)
similarity.functions <- vector(mode="list", length=3)
names(similarity.functions) <- c("Contemporaneity", "Locality", "Genre")
similarity.functions[[1]] <- similarity.function.contemporaneity; similarity.functions[[2]] <- similarity.function.locality
similarity.functions[[3]] <- similarity.function.genre

distance.functions <- vector(mode="list", length=3)
names(distance.functions) <- c("Contemporaneity", "Locality", "Genre")
distance.functions[[1]] <- distance.function.contemporaneity; distance.functions[[2]] <- distance.function.locality
distance.functions[[3]] <- distance.function.genre


#################### Calculate frequencies for IOF for type and Locality  ####################

by.area = group_by(artist.data,area)
freq.area = dplyr::summarise(by.area, total = n())

```

```{r}

################################## ShiftBand Constants ###################################

ALPHA = 0.1
BETA = 0.1
GAMMA = 0.1
ETA = 0.1
K = nrow(artist.data) # Number of scenarios
TRIALS = 10 
S = 200000

```

```{r}

########################################## MAB ##########################################

#ShiftBand implemented as seen in
# AUER, Peter. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, v. 3, n. Nov, p. 397-422, 2002.

  random.probability.sort = function(p){
    total = sum(p)
    target = runif(1, 0, total)
    i = 1
    while(total - p[i] > target){
      total = total - p[i]
      i = i + 1
    }
    return(i)
  }

  set.probability = function(i, w, W){
    return((1 - GAMMA) * w[i] / W + GAMMA / K)
  }
  
  set.weights = function(i, w, W, p, x.exp){
    return(w[i] * exp(ETA * (x.exp[i] + ALPHA / (p[i] * sqrt(TRIALS * K / S))))) # S = number of days)
  }
  
  set.probability.matrix = function(n, w.matrix, W) {
    lapply(c(1:K), set.probability, w.matrix[n,], W[n]) %>% as.numeric()
  }

# user = users[1]
# history = data.train
one.user.momab.shiftband = function(user, history){
  
  # TO DO - determine user propensity using ILDPD
  
  user.history = history[which(history$`user-id` == user),] %>% select(`artist-name`)
  names(user.history) = "Artist"
  data.train.user = inner_join(user.history, artist.data, by = "Artist")
    
  # setup ShiftBand
  w.matrix.diversity = matrix(nrow = REC.SIZE, ncol = K)
  w.matrix.diversity[,] = 1
  w.matrix.affinity = w.matrix.diversity

  # ranked MAB ShiftBand

  select.rec.list = function(n, p1, p2){
    p = (p1[n,] + p2[n,]) / 2
    item = random.probability.sort(p)
    p1[,item] = 0
    p2[,item] = 0
    return(item)
  }

  for (i in 1:S) { # each user iteraction

    W.diversity = do.call(cbind, lapply(c(1:REC.SIZE), function(x) sum(w.matrix.diversity[x,]))) %>% as.vector()
    W.affinity = do.call(cbind, lapply(c(1:REC.SIZE), function(x) sum(w.matrix.affinity[x,]))) %>% as.vector()
    p.diversity = do.call(rbind, lapply(c(1:REC.SIZE), set.probability.matrix, w.matrix.diversity, W.diversity))
    p.affinity = do.call(rbind, lapply(c(1:REC.SIZE), set.probability.matrix, w.matrix.affinity, W.affinity))

    # mount recommendation list
    p.diversity.copy = p.diversity
    p.affinity.copy = p.affinity
    rec.list = do.call(cbind, (lapply(c(1:REC.SIZE), select.rec.list, p.diversity.copy, p.affinity.copy))) %>% as.vector()
    
    # collect reward
    reward = multi.objective(rec.list)
    
    
    
  }
    
}

```

