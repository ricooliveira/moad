---
title: "R Notebook"
output: html_notebook
---

```{r}

if (!require("dplyr")) {
  install.packages("dplyr", repos="http://cran.rstudio.com/") 
}
if (!require("data.table")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("pbapply")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("ggplot2")) {
  install.packages("data.table", repos="http://cran.rstudio.com/") 
}
if (!require("reshape")) {
  install.packages("reshape", repos="http://cran.rstudio.com/") 
}

library(dplyr)
library(data.table)
library(pbapply)
library(ggplot2)
library(reshape)
library(lsa)
library(recommenderlab)

```

```{r}

REC.SIZE = 10
TEST.SIZE = 20
address <- "/home/ricardo/DataScience/moad/"

# aspects setup
# aspects: 1 = "Contemporaneity", 2 = "Locality", 3 = "Genre")
#for(aspect.index in 1:4){
aspects.all = c(1,2,3)

```

```{r}

########################################## Metric Functions ##########################################

# Intra List Diversity Metric (ILD)

similarity.function.genre = function(data){
  return(cosine(t(as.matrix(data))))
}

similarity.function.locality = function(data){
  n = nrow(data)
  m = matrix(0L,n,n)
  N = nrow(artist.data)
  for(i in 1:n){
    for(j in 1:n){
      if(data[i,"area"] == data[j,"area"]){
        m[i,j] = 1
      } else {  
        m[i,j] = 1 / (1 + log10(N/(as.numeric(freq.area[which(data[i,"area"] == freq.area$area),"total"]))) 
                        * log10(N/(as.numeric(freq.area[which(data[j,"area"] == freq.area$area),"total"]))))
      }
    }
  }
  return(m)
}

similarity.function.contemporaneity = function(data){
  artistas = rownames(data)
  data$artista = artistas
  artist_simi = combn(artistas, 2) %>% t() %>% as_data_frame()

  sim_between_artists = function(x, data){
    a = x[1]
    b = x[2]
    a_data =  data %>% filter(artista %in% a)
    b_data =  data %>% filter(artista %in% b)
    
    pc = min(a_data$debut, b_data$debut)
    ut = max(a_data$last, b_data$last)
    
    uc = max(a_data$debut, b_data$debut)
    pt = min(a_data$last, b_data$last)
    
    if (ut == pc)
      return(1)
    
    sim = (pt - uc)/(ut - pc)
    return((sim+1)/2)
  }
  
  sim = apply(artist_simi, 1, sim_between_artists, data)
  artist_simi$sim = sim
  artist_simi_replicated = artist_simi %>% select(V1=V2, V2=V1, sim)
  artists_identity = data.frame(V1 = artistas, V2 = artistas, sim = 1)
  artist_simi = rbind(artist_simi, artist_simi_replicated, artists_identity)
  
  matrix = artist_simi %>% cast(V1~V2, mean, value = "sim") %>% select(-V1)
  
  matrix = matrix %>% as.matrix()
  return(matrix)
}

ILD = function(data, similarity.function){
  k=nrow(data)
  if(k > 1){
    sum.dissimilarity = 0
    similarity.matrix = similarity.function(data)
    dissimilarity.matrix = 1 - similarity.matrix
    sum.dissimilarity = sum(colSums(dissimilarity.matrix))
    return(sum.dissimilarity/(k*(k-1)))
  }else{
    return(0)
  }
}

list.ILD = function(list.elements){
  list.elements = list.elements %>% as.data.frame()
  size = nrow(list.elements)
  # list.elements = as.data.frame(artist.data[list.elements.index,"Artist"])
  names(list.elements) = "artist"
  # n = length(aspects.to.diversify)
  df = artist.data[artist.data$Artist %in% list.elements$artist,]
  
  return(c(
            ILD(df[(aspects[[1]])], similarity.function.contemporaneity),
            ILD(df[(aspects[[2]])], similarity.function.locality),
            ILD(df[(aspects[[3]])], similarity.function.genre))
          )
}

# Distance List History Metric (DLH)

distance.function.genre = function(data, history){
  centroid = genre.centroids[which(genre.centroids$`user-id` == user),]
  centroid$`user-id` = NULL
  distance = 0
  for(i in 1:nrow(data)){
    distance = distance + cosine(as.vector(t(data[i,])),as.vector(t(centroid)))
  }
  return(distance/nrow(data))
}

distance.function.locality = function(data, history){
  rec <- as.vector(t(data))
  h <- as.vector(t(history))
  N = nrow(artist.data)
  
  rec.g <- sapply(rec, function(x) {freq.area[which(x == freq.area$area), ]$total})
  h.g <- sapply(h, function(x) {freq.area[which(x == freq.area$area), ]$total})
  
  f <- function(i, j) {
    ifelse(i == j, 1, 1 / (1 + log10(N/i) * log10(N/j)))
  }
  
  r <- outer(rec.g, h.g, f)
  return(mean(r))
}

distance.function.contemporaneity = function(data, history){

  n = nrow(data)
  m = nrow(history)
  data$index = c(1:nrow(n))
  history$index = c(1:nrow(m))
  # artist_simi = combn(artistas, 2) %>% t() %>% as_data_frame()

  sim_between_artists_history = function(x, data, history){
    a = x[1]
    b = x[2]
    a_data =  data %>% filter(index %in% a)
    b_history =  history %>% filter(index %in% b)
    
    pc = min(a_data$debut, b_history$debut)
    ut = max(a_data$last, b_history$last)
    
    uc = max(a_data$debut, b_history$debut)
    pt = min(a_data$last, b_history$last)
    
    sim = (pt - uc)/(ut - pc)
    
    return((sim+1)/2)
  }
   
  sum.contemporaneity = 0
  for(i in 1:n){
    for(j in 1:m){
      sum.contemporaneity = sum.contemporaneity + sim_between_artists_history(c(i,j), data, history)
    }
  }
  return(sum.contemporaneity / (m * n))
}

DLH = function(data, history, distance.function){
  return(distance.function(data, history))
}

```

```{r}

########################## DATA LOAD ############################

data.train <- fread(paste0(address,"data/LFM_train.txt"), 
                    sep = "\t", 
                    verbose = TRUE,
                    header = TRUE)
data.train = as.data.frame(data.train)
names(data.train) = c("albumid", "artistid", "userid", "timestamp", "country", "age", "gender", "playcount", "regtimestamp", "artistname", "albumname")

# data.test <- fread(paste0(address,"data/LFM_test.txt"), 
#                     sep = "\t", 
#                     verbose = TRUE,
#                     header = TRUE)
# data.test = as.data.frame(data.test)

artist.data <- fread(paste0(address,"data/artist.data.txt"), 
                     sep = ";", 
                     verbose = TRUE,
                     header = TRUE)
artist.data = as.data.frame(artist.data)
#test: artist.data = artist.data[1:TEST.SIZE,]
# data.train = data.train[data.train$artistname %in% artist.data$Artist,]

# Correcting debut year from Rod Stewart - wrong in MusicBrainz

artist.data[which(artist.data$Artist == "The_Pains_of_Being_Pure_at_Heart"),"last"] = 2017
artist.data[which(artist.data$Artist == "Rod_Stewart"),"debut"] = 1968

# Input 0 in NA values

col = c(3:6)
for(i in col){
  artist.data[which(is.na(artist.data[,i])),i] = 0
}

genre.centroids <- fread(paste0(address,"data/user.history.centroids.txt"), 
                    sep = ",", 
                    verbose = TRUE,
                    header = TRUE)
genre.centroids = as.data.frame(genre.centroids)

users = data.train$userid %>% unique()

```

```{r}

################################ OBJECTIVE FUNCTION ################################

# This function will be executed for a user, with specific data.test, specified aspects to diversify and a determined 
# list size (TOPN)

# list.elements.index = rec.list

multi.objective = function(list.elements.index){
   size = length(list.elements.index)
   list.elements = as.data.frame(artist.data[list.elements.index,"Artist"])
   names(list.elements) = "artist"
   n = length(aspects.to.diversify)
   df = artist.data[artist.data$Artist %in% list.elements$artist,]
   
   sum.ild = 0
   for(i in aspects.to.diversify){
     df.aspect = df[(aspects[[i]])]
     sum.ild = sum.ild + ILD(data = df.aspect, similarity.function = similarity.functions[[i]])
   }
   y1 = (sum.ild / n)
   
   sum.dlh = 0
   for(i in aspects.not.to.diversify){
     df.aspect = df[(aspects[[i]])]
     sum.dlh = sum.dlh + DLH(data = df.aspect, history = data.train.user[(aspects[[i]])], distance.function = distance.functions[[i]])
   }
   y2 = (sum.dlh / length(aspects.not.to.diversify))
   
   return(c(y1, y2))
}

```

```{r}

########################################## ASPECTS ##########################################

aspects <- vector(mode="list", length=3)
names(aspects) <- c("Contemporaneity", "Locality", "Genre")
aspects[[1]] <- c(5,6); aspects[[2]] <- 4; aspects[[3]] <- 7:ncol(artist.data)
similarity.functions <- vector(mode="list", length=3)
names(similarity.functions) <- c("Contemporaneity", "Locality", "Genre")
similarity.functions[[1]] <- similarity.function.contemporaneity; similarity.functions[[2]] <- similarity.function.locality
similarity.functions[[3]] <- similarity.function.genre

distance.functions <- vector(mode="list", length=3)
names(distance.functions) <- c("Contemporaneity", "Locality", "Genre")
distance.functions[[1]] <- distance.function.contemporaneity; distance.functions[[2]] <- distance.function.locality
distance.functions[[3]] <- distance.function.genre


#################### Calculate frequencies for IOF for type and Locality  ####################

by.area = group_by(artist.data,area)
freq.area = dplyr::summarise(by.area, total = n())

```

```{r}

################################## ShiftBand Constants ###################################

ALPHA = 0.1
BETA = 0.1
GAMMA = 0.1
ETA = 0.1
K = 1000 # Number of artists - UBCF
TRIALS = K * 10 
S = 1

```

```{r}
################################# MEDIAN ILD ########################################

# clean zeros and median

all.ilds = fread(paste0(address,"results/daily.propensity.ILD.allusers.txt"), 
                     sep = ",")
all.ilds = as.data.frame(all.ilds)

names(all.ilds) = c("day", "contemporaneity", "locality", "genre")
all.ilds.filtered = filter(all.ilds, contemporaneity > 0 & locality > 0 & genre > 0)

median.ild = c(median(all.ilds.filtered$contemporaneity), median(all.ilds.filtered$locality), median(all.ilds.filtered$genre))

```

```{r}
################################# USER PROPENSITY ########################################
# 
# user.propensity = function(user, history, median.ild){
#   print(user)
#   user.history = history[which(history$userid == user),] %>% select(artistname)
#   names(user.history) = "Artist"
#   user.history = user.history %>% unique()
#   user.ilds = list.ILD(user.history)
#   return(user.ilds > median.ild)
# }
# 
# # batch process and save
# propensities = do.call(rbind, lapply(users, user.propensity, history, median.ild))
# user.propensities = cbind(users, propensities) %>% as.data.frame()
# names(user.propensities) = c("userid", "div.contemporaneity", "div.locality", "div.genre")
# 
# fwrite(user.propensities,
#        paste0(address, "resultsmomab/user.propensities.txt"),
#        col.names = TRUE, row.names = FALSE, quote = TRUE)

propensities = fread(paste0(address,"resultsmomab/user.propensities.txt"), 
                          sep = ",", 
                          header = TRUE)

```

```{r}
############################## UBCF ##############################

# Transforming LFM.artists.available in a rating matrix - Artists rating

artists.listenned = unique(data.train$artistname)

byUserArtist = group_by(data.train, userid, artistname)
sumArtistsUser = summarise(byUserArtist,total = n())

colnames(sumArtistsUser) = c("user", "item", "rating")
sumArtistsUser = as.data.frame(sumArtistsUser)
affinity.matrix = as(sumArtistsUser,"realRatingMatrix")

Rec.model = Recommender(affinity.matrix,
                        method="UBCF", 
                        param=list(normalize = "Z-score",
                                   method="Cosine",
                                   nn=5))

ubcf.top.rerank = vector("list",length(users))

# Generate UBCF Top K Recommendations
for(i in 1:length(users)){ # refazer pra tirar o laço. Usar stack. Data frame transforma elementos em fatores, atrapalha o stack
  print(i)
  recommended.items <- predict(Rec.model, affinity.matrix[as.character(users[i]),], n = K)
  ubcf.top.rerank[[i]] = as.data.frame(as(recommended.items, "list"))
}

# Write UBCF Top 50 Recommendations
for(i in 1:length(users)){
  print(i)
  df.user = as.data.frame(matrix(as.character(users[i]),TOPN_RERANK,1))
  df.user = bind_cols(df.user, ubcf.top.rerank[[i]])
  fwrite(df.user, 
         paste0(address,"bases de dados/experimento/sample1000.ubcf.top50.csv"),
         row.names = FALSE, col.names = FALSE, sep = ";", append = TRUE, quote = TRUE)
}
```

```{r}

########################################## MAB ##########################################

# Multiobjective Ranked ShiftBand
#ShiftBand implemented as seen in
# AUER, Peter. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, v. 3, n. Nov, p. 397-422, 2002.

  random.probability.sort = function(p){
    total = sum(p)
    target = runif(1, 0, total)
    i = 1
    while(total - p[i] > target){
      total = total - p[i]
      i = i + 1
    }
    return(i)
  }

  set.probability = function(i, w, W){
    return((1 - GAMMA) * w[i] / W + GAMMA / K)
  }
  
  set.weights = function(i, w, p, x.exp){
    return(w[i] * exp(ETA * (x.exp[i] + ALPHA / (p[i] * sqrt(TRIALS * K / S))))) # S = number of days)
  }
  
  set.probability.matrix = function(n, w.matrix, W) {
    lapply(c(1:K), set.probability, w.matrix[n,], W[n]) %>% as.numeric()
  }

# user = users[2]
one.user.momab.shiftband = function(user){
  
  artist.data.listenned = unique(data.train[which(data.train$userid == user),]$artistname)
  data.train.user = artist.data[artist.data$Artist %in% artist.data.listenned,]
  
  # setup ShiftBand
  w.matrix.diversity = matrix(data = 1, nrow = REC.SIZE, ncol = K)
  w.matrix.affinity = w.matrix.diversity

  # ranked MAB ShiftBand
  
  # i = 1
  for (i in 1:TRIALS) { # each user iteraction

    W.diversity = do.call(cbind, lapply(c(1:REC.SIZE), function(x) sum(w.matrix.diversity[x,]))) %>% as.vector()
    W.affinity = do.call(cbind, lapply(c(1:REC.SIZE), function(x) sum(w.matrix.affinity[x,]))) %>% as.vector()
    p.diversity = do.call(rbind, lapply(c(1:REC.SIZE), set.probability.matrix, w.matrix.diversity, W.diversity))
    p.affinity = do.call(rbind, lapply(c(1:REC.SIZE), set.probability.matrix, w.matrix.affinity, W.affinity))

    # mount recommendation list
    p.diversity.copy = p.diversity
    p.affinity.copy = p.affinity
    rec.list = c()
    for (n in 1:REC.SIZE){
      p = (p.diversity.copy[n,] + p.affinity.copy[n,]) / 2
      item = random.probability.sort(p)
      p.diversity.copy[,item] = 0
      p.affinity.copy[,item] = 0
      rec.list = c(rec.list, item)
    }
    # rec.list = do.call(cbind, (lapply(c(1:REC.SIZE), select.rec.list, p.diversity.copy, p.affinity.copy))) %>% as.vector()
    
    # COLLECT REWARD
    
    # determine user propensity using history ILD
  
    # online
    # user.prop = user.propensity(user, history, median.ild)  
    # batch
    # user.prop = fread(paste0(address,"resultsmomab/user.propensities.txt"), sep = "\t", header = TRUE)
    
    # propensities = c(TRUE, TRUE, FALSE) #testing
    user.prop = propensities %>% filter(userid == user) %>% select(div.contemporaneity, div.locality, div.genre)
    aspects.to.diversify = which(user.prop == 1)
    aspects.not.to.diversify = setdiff(aspects.all,aspects.to.diversify)
    
    reward = multi.objective(rec.list)
    
    # set xit
    xit.diversity = matrix(data = 0.0, nrow = REC.SIZE, ncol = K)
    xit.affinity = matrix(data = 0.0, nrow = REC.SIZE, ncol = K)
    
    #xit = xit.diversity
    #p = p.diversity
    for(pos in 1:REC.SIZE){
      xit.diversity[pos, rec.list[pos]] = reward[1] / p.diversity[pos, rec.list[pos]]
      xit.affinity[pos, rec.list[pos]] = reward[2] / p.affinity[pos, rec.list[pos]]
    }
    # update.xit = function(pos, xit, p, reward){
    #   xit[pos, rec.list[pos]] = reward / p[pos, rec.list[pos]]
    # }
    # 
    # lapply(c(1:REC.SIZE), update.xit, xit.diversity, p.diversity, reward[1])
    # lapply(c(1:REC.SIZE), update.xit, xit.affinity, p.affinity, reward[2])
    
    # update weights
    # pos = 1
    for(pos in 1:REC.SIZE){
      w.matrix.diversity[pos, ] = lapply(c(1:K), set.weights, w.matrix.diversity[pos,], 
                                       p.diversity[pos,], xit.diversity[pos,]) %>% as.numeric()
      w.matrix.affinity[pos, ] = lapply(c(1:K), set.weights, w.matrix.affinity[pos,], 
                                       p.affinity[pos,], xit.affinity[pos,]) %>% as.numeric()
    }
  fwrite(reward %>% as.data.frame() %>% t() %>% as.data.frame(),
           paste0(address,"resultsmomab/momab.shiftband.rewards.user",user,".txt"), 
           col.names = FALSE, row.names = FALSE, sep = "\t", append = TRUE)
  }  
}
start.time <- Sys.time()

one.user.momab.shiftband(user)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

lapply(users, one.user.momab.shiftband)

```

